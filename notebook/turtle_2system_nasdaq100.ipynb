{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"//code.highcharts.com/stock/highstock.js\"></script>\n",
       "<script src=\"//code.highcharts.com/highcharts-more.js\"></script>\n",
       "<script src=\"//code.highcharts.com/modules/exporting.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import empyrical as emp\n",
    "import time\n",
    "import random\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from common.log import *\n",
    "from common.config import Config\n",
    "from spider.spider_nasdaq import Spider_nasdaq\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from pandas_highcharts.core import serialize\n",
    "from pandas_highcharts.display import display_charts\n",
    "\n",
    "CONF = Config().data[0]\n",
    "MONGODB = CONF['MONGODB']\n",
    "NASDAQ = CONF['NASDAQ']\n",
    "CRYPTOCURRENCY = CONF['CRYPTOCURRENCY']\n",
    "NASDAQ100 = CONF['NASDAQ100']\n",
    "\n",
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../database/market/NDX.csv\n",
      "../database/market/TSLA.csv\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "spider = Spider_nasdaq()\n",
    "timeframe = '10y'\n",
    "ignore = True\n",
    "\n",
    "# for symbol in NASDAQ100:\n",
    "for symbol in ['NDX', 'TSLA']:\n",
    "#     if symbol == 'SHPG':\n",
    "#         ignore = False\n",
    "#     if ignore:\n",
    "#         continue\n",
    "    datafile = spider.get_stock_data(symbol, timeframe)\n",
    "    print(datafile)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### 时间设置\n",
    "start_date = '2008-06-02'\n",
    "start_date = '2010-01-01'\n",
    "# start_date = '2015-01-01'\n",
    "# start_date = '2017-01-03'\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "TURTLE_POS = 20\n",
    "### Turtle System One - Short\n",
    "TURTLE_SHORT_BUY_N = 20\n",
    "TURTLE_SHORT_SELL_N = 20\n",
    "### Turtle System Two - Long\n",
    "TURTLE_LONG_BUY_N = 60\n",
    "TURTLE_LONG_SELL_N = 60\n",
    "\n",
    "### 业务设置\n",
    "IS_HAPPYMONEY = False\n",
    "IS_TAX = False\n",
    "IS_SLIPPAGE = True\n",
    "IS_RANDOM_BUY = True\n",
    "START_MONEY = 100000\n",
    "HAPPY_MONEY = 0\n",
    "PROPERTY = START_MONEY\n",
    "CASH = START_MONEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stock_df_dict = {}\n",
    "\n",
    "for symbol in NASDAQ100[:]:\n",
    "    stock_data_file = '../database/market/%s.csv' % symbol\n",
    "    stock_df = pd.read_csv(stock_data_file)\n",
    "\n",
    "    # 筛选字段\n",
    "#     stock_df = stock_df.loc[:, ['date', 'open', 'close']]\n",
    "\n",
    "    # 去掉Nasdaq行情首行的当天行情\n",
    "    if symbol in NASDAQ:\n",
    "        stock_df = stock_df.drop([0])\n",
    "\n",
    "    # 抛弃空值异常值\n",
    "    stock_df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    # 格式化日期\n",
    "    # 1.48 s ± 45.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "#     stock_df['date'] = stock_df['date'].apply(lambda x: pd.Period(x, freq='D'))\n",
    "\n",
    "    # 445 ms ± 17.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "    stock_df = stock_df.assign(date=pd.to_datetime(stock_df['date']))  # need .index.to_period('D')\n",
    "\n",
    "    # 476 ms ± 46.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "#     stock_df['date'] = pd.to_datetime(stock_df['date'])  # need .index.to_period('D')\n",
    "    \n",
    "    # 转换字段格式\n",
    "#     stock_df = stock_df.astype(dtype={'volume': 'float64'})\n",
    "\n",
    "    # 用日期作索引，日期升序排序\n",
    "    # 95.1 µs ± 1.58 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "    stock_df = stock_df[::-1]\n",
    "    \n",
    "    # 407 µs ± 5.07 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "#     %timeit stock_df.set_index(['date'], inplace=False)\n",
    "\n",
    "    # Wall time: 500 µs\n",
    "    stock_df.set_index(['date'], inplace=True)\n",
    "    \n",
    "    # 305 µs ± 2.75 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "#     stock_df = stock_df.sort_index(axis=0, ascending=True)\n",
    "    \n",
    "    # 822 µs ± 41.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "    stock_df.index = stock_df.index.to_period('D')\n",
    "\n",
    "    # 计算涨跌幅\n",
    "#     stock_df['c_pct_chg'] = stock_df.close.pct_change(1)\n",
    "    stock_df['o_pct_chg'] = stock_df.open.pct_change(1)\n",
    "    \n",
    "    # Turtle指标\n",
    "#     stock_df['TR1'] = abs(stock_df['high'] - stock_df['low'])\n",
    "#     stock_df['TR2'] = abs(stock_df['high'] - stock_df['close'].shift())\n",
    "#     stock_df['TR3'] = abs(stock_df['low'] - stock_df['close'].shift())\n",
    "#     stock_df['TR'] = stock_df[['TR1', 'TR2', 'TR3']].max(axis=1)\n",
    "#     stock_df['N'] = stock_df['TR'].rolling(20).mean()\n",
    "#     stock_df['UNIT'] = (0.01 * START_MONEY) / (stock_df['N'])\n",
    "    stock_df['ROLLING_%d_MAX' % TURTLE_SHORT_BUY_N] = stock_df['open'].rolling(TURTLE_SHORT_BUY_N).max()\n",
    "    stock_df['ROLLING_%d_MIN' % TURTLE_SHORT_SELL_N] = stock_df['open'].rolling(TURTLE_SHORT_SELL_N).min()\n",
    "    stock_df['ROLLING_%d_MAX' % TURTLE_LONG_BUY_N] = stock_df['open'].rolling(TURTLE_LONG_BUY_N).max()\n",
    "    stock_df['ROLLING_%d_MIN' % TURTLE_LONG_SELL_N] = stock_df['open'].rolling(TURTLE_LONG_SELL_N).min()\n",
    "#     stock_df['MA%d' % TURTLE_BUY_N] = stock_df['open'].rolling(TURTLE_BUY_N).mean()\n",
    "#     stock_df['MA%d' % TURTLE_SELL_N] = stock_df['open'].rolling(TURTLE_SELL_N).mean()\n",
    "#     stock_df['EWMA'] = stock_df['open'].ewm(alpha=0.1, adjust=False).mean()\n",
    "    stock_df['MA360'] = stock_df['open'].rolling(360).mean()\n",
    "    stock_df['MA180'] = stock_df['open'].rolling(180).mean()\n",
    "    stock_df['MA60'] = stock_df['open'].rolling(30).mean()\n",
    "    stock_df['MA30'] = stock_df['open'].rolling(30).mean()\n",
    "    \n",
    "#     stock_df['ops'] = ''\n",
    "#     stock_df['profit'] = 0\n",
    "    \n",
    "    # 减少数据\n",
    "    # stock_df = stock_df['2016-01-01':]\n",
    "    stock_df.dropna(how='any', inplace=True)\n",
    "#     stock_df.drop(columns=['volume', 'TR1', 'TR2', 'TR3'], inplace=True)\n",
    "    \n",
    "    stock_df_dict[symbol] = stock_df\n",
    "    \n",
    "#     print(stock_df.head(10))\n",
    "#     print(stock_df.dtypes)\n",
    "#     print(stock_df.index[0])\n",
    "#     print(type(stock_df.index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'volume', 'o_pct_chg', 'ROLLING_20_MAX',\n",
       "       'ROLLING_20_MIN', 'ROLLING_60_MAX', 'ROLLING_60_MIN', 'MA360', 'MA180',\n",
       "       'MA60', 'MA30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>o_pct_chg</th>\n",
       "      <th>ROLLING_20_MAX</th>\n",
       "      <th>ROLLING_20_MIN</th>\n",
       "      <th>ROLLING_60_MAX</th>\n",
       "      <th>ROLLING_60_MIN</th>\n",
       "      <th>MA360</th>\n",
       "      <th>MA180</th>\n",
       "      <th>MA60</th>\n",
       "      <th>MA30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-26</th>\n",
       "      <td>336.054</td>\n",
       "      <td>343.5500</td>\n",
       "      <td>325.799</td>\n",
       "      <td>342.00</td>\n",
       "      <td>7434749</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>365.16</td>\n",
       "      <td>283.290</td>\n",
       "      <td>365.16</td>\n",
       "      <td>252.780</td>\n",
       "      <td>317.910435</td>\n",
       "      <td>318.751732</td>\n",
       "      <td>312.617567</td>\n",
       "      <td>312.617567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-27</th>\n",
       "      <td>345.000</td>\n",
       "      <td>350.7900</td>\n",
       "      <td>339.500</td>\n",
       "      <td>344.50</td>\n",
       "      <td>8313817</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>365.16</td>\n",
       "      <td>285.860</td>\n",
       "      <td>365.16</td>\n",
       "      <td>252.780</td>\n",
       "      <td>318.185852</td>\n",
       "      <td>318.725898</td>\n",
       "      <td>314.617233</td>\n",
       "      <td>314.617233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>348.660</td>\n",
       "      <td>357.0200</td>\n",
       "      <td>346.110</td>\n",
       "      <td>349.93</td>\n",
       "      <td>8388172</td>\n",
       "      <td>0.010609</td>\n",
       "      <td>365.16</td>\n",
       "      <td>285.860</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>318.459908</td>\n",
       "      <td>318.736232</td>\n",
       "      <td>316.778233</td>\n",
       "      <td>316.778233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-29</th>\n",
       "      <td>353.330</td>\n",
       "      <td>353.8600</td>\n",
       "      <td>342.410</td>\n",
       "      <td>342.95</td>\n",
       "      <td>6475903</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>365.16</td>\n",
       "      <td>294.340</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>318.726630</td>\n",
       "      <td>318.733121</td>\n",
       "      <td>319.025900</td>\n",
       "      <td>319.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>360.070</td>\n",
       "      <td>364.7800</td>\n",
       "      <td>329.850</td>\n",
       "      <td>335.07</td>\n",
       "      <td>18732710</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>365.16</td>\n",
       "      <td>297.700</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>319.020463</td>\n",
       "      <td>318.772676</td>\n",
       "      <td>321.539900</td>\n",
       "      <td>321.539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03</th>\n",
       "      <td>331.750</td>\n",
       "      <td>332.4900</td>\n",
       "      <td>309.690</td>\n",
       "      <td>310.86</td>\n",
       "      <td>12282640</td>\n",
       "      <td>-0.078651</td>\n",
       "      <td>365.16</td>\n",
       "      <td>300.500</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>319.243713</td>\n",
       "      <td>318.632509</td>\n",
       "      <td>323.220567</td>\n",
       "      <td>323.220567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>313.760</td>\n",
       "      <td>314.3900</td>\n",
       "      <td>296.220</td>\n",
       "      <td>309.16</td>\n",
       "      <td>17457570</td>\n",
       "      <td>-0.054228</td>\n",
       "      <td>365.16</td>\n",
       "      <td>313.760</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>319.413796</td>\n",
       "      <td>318.410287</td>\n",
       "      <td>324.087167</td>\n",
       "      <td>324.087167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-06</th>\n",
       "      <td>304.955</td>\n",
       "      <td>312.0700</td>\n",
       "      <td>302.000</td>\n",
       "      <td>308.90</td>\n",
       "      <td>8860198</td>\n",
       "      <td>-0.028063</td>\n",
       "      <td>365.16</td>\n",
       "      <td>304.955</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>319.568560</td>\n",
       "      <td>318.154982</td>\n",
       "      <td>324.993667</td>\n",
       "      <td>324.993667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-09</th>\n",
       "      <td>311.990</td>\n",
       "      <td>318.5200</td>\n",
       "      <td>308.000</td>\n",
       "      <td>318.51</td>\n",
       "      <td>7579541</td>\n",
       "      <td>0.023069</td>\n",
       "      <td>365.16</td>\n",
       "      <td>304.955</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>319.732283</td>\n",
       "      <td>317.910648</td>\n",
       "      <td>326.113333</td>\n",
       "      <td>326.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-10</th>\n",
       "      <td>324.560</td>\n",
       "      <td>327.6771</td>\n",
       "      <td>319.200</td>\n",
       "      <td>322.47</td>\n",
       "      <td>9437557</td>\n",
       "      <td>0.040290</td>\n",
       "      <td>365.16</td>\n",
       "      <td>304.955</td>\n",
       "      <td>365.16</td>\n",
       "      <td>277.625</td>\n",
       "      <td>319.944005</td>\n",
       "      <td>317.738426</td>\n",
       "      <td>327.677833</td>\n",
       "      <td>327.677833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open      high      low   close    volume  o_pct_chg  \\\n",
       "date                                                                  \n",
       "2018-06-26  336.054  343.5500  325.799  342.00   7434749   0.017975   \n",
       "2018-06-27  345.000  350.7900  339.500  344.50   8313817   0.026621   \n",
       "2018-06-28  348.660  357.0200  346.110  349.93   8388172   0.010609   \n",
       "2018-06-29  353.330  353.8600  342.410  342.95   6475903   0.013394   \n",
       "2018-07-02  360.070  364.7800  329.850  335.07  18732710   0.019076   \n",
       "2018-07-03  331.750  332.4900  309.690  310.86  12282640  -0.078651   \n",
       "2018-07-05  313.760  314.3900  296.220  309.16  17457570  -0.054228   \n",
       "2018-07-06  304.955  312.0700  302.000  308.90   8860198  -0.028063   \n",
       "2018-07-09  311.990  318.5200  308.000  318.51   7579541   0.023069   \n",
       "2018-07-10  324.560  327.6771  319.200  322.47   9437557   0.040290   \n",
       "\n",
       "            ROLLING_20_MAX  ROLLING_20_MIN  ROLLING_60_MAX  ROLLING_60_MIN  \\\n",
       "date                                                                         \n",
       "2018-06-26          365.16         283.290          365.16         252.780   \n",
       "2018-06-27          365.16         285.860          365.16         252.780   \n",
       "2018-06-28          365.16         285.860          365.16         277.625   \n",
       "2018-06-29          365.16         294.340          365.16         277.625   \n",
       "2018-07-02          365.16         297.700          365.16         277.625   \n",
       "2018-07-03          365.16         300.500          365.16         277.625   \n",
       "2018-07-05          365.16         313.760          365.16         277.625   \n",
       "2018-07-06          365.16         304.955          365.16         277.625   \n",
       "2018-07-09          365.16         304.955          365.16         277.625   \n",
       "2018-07-10          365.16         304.955          365.16         277.625   \n",
       "\n",
       "                 MA360       MA180        MA60        MA30  \n",
       "date                                                        \n",
       "2018-06-26  317.910435  318.751732  312.617567  312.617567  \n",
       "2018-06-27  318.185852  318.725898  314.617233  314.617233  \n",
       "2018-06-28  318.459908  318.736232  316.778233  316.778233  \n",
       "2018-06-29  318.726630  318.733121  319.025900  319.025900  \n",
       "2018-07-02  319.020463  318.772676  321.539900  321.539900  \n",
       "2018-07-03  319.243713  318.632509  323.220567  323.220567  \n",
       "2018-07-05  319.413796  318.410287  324.087167  324.087167  \n",
       "2018-07-06  319.568560  318.154982  324.993667  324.993667  \n",
       "2018-07-09  319.732283  317.910648  326.113333  326.113333  \n",
       "2018-07-10  319.944005  317.738426  327.677833  327.677833  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'pandas._libs.tslibs.period.Period'> is not convertible to datetime",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6dba41cef2e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'datetime64[ns]'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# df.index.astype()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   4984\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4985\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4986\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4987\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4988\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   4995\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4996\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 4997\u001b[1;33m                                          **kwargs)\n\u001b[0m\u001b[0;32m   4998\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3713\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3714\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3716\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 575\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_datetime64_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_timedelta64_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_timedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_and_box_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[1;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[0;32m    366\u001b[0m                     \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                     \u001b[0myearfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m                     \u001b[0mrequire_iso8601\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequire_iso8601\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m                 )\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'pandas._libs.tslibs.period.Period'> is not convertible to datetime"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [30, 20]\n",
    "\n",
    "df = stock_df_dict['TSLA'].iloc[800:].copy()\n",
    "df.columns\n",
    "df.tail(10)\n",
    "# df[(df.open == df.rolling_60_max)]\n",
    "# df[(df.open >= df.rolling_60_max) & (df.MA30 > df.MA60)]\n",
    "# df[(df.MA30 > df.MA60)]\n",
    "\n",
    "# df = df.loc[:, ['open', 'ROLLING_60_MAX', 'rolling_30_min', 'MA60', 'MA30']]\n",
    "\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "df = df.astype(dtype={'date': 'datetime64[ns]'})\n",
    "df.set_index('date', inplace=True)\n",
    "# df.index.astype()\n",
    "\n",
    "display_charts(df, chart_type='stock', kind='line', y=['open', 'ROLLING_60_MAX', 'ROLLING_60_MIN'], figsize=(900, 600), logy=False)\n",
    "\n",
    "# display_charts(df)\n",
    "\n",
    "# ax = df.plot(kind='line', y=['open', 'rolling_max', 'rolling_min'], label='', linewidth=1)\n",
    "\n",
    "# sum_buy_sig_short = 0\n",
    "# sum_buy_sig_long = 0\n",
    "# for symbol in NASDAQ100:\n",
    "#     tdf = stock_df_dict[symbol]\n",
    "#     buy_sig_short = tdf[(stock_df_dict[symbol].open == stock_df_dict[symbol]['ROLLING_%d_MAX' % TURTLE_SHORT_BUY_N])]\n",
    "#     buy_sig_long = tdf[(stock_df_dict[symbol].open == stock_df_dict[symbol]['ROLLING_%d_MAX' % TURTLE_LONG_BUY_N])]\n",
    "#     buy_sig_short_2 = buy_sig_short[buy_sig_short.MA30 >= buy_sig_short.MA180]\n",
    "#     buy_sig_long_2 = buy_sig_long[buy_sig_long.MA30 >= buy_sig_long.MA180]\n",
    "# #     print(symbol, len(tdf), len(buy_sig_short), len(buy_sig_short_2), len(buy_sig_long), len(buy_sig_long_2))\n",
    "#     sum_buy_sig_short += len(buy_sig_short_2)\n",
    "#     sum_buy_sig_long += len(buy_sig_long_2)\n",
    "# print(len(stock_df_dict['NDX']), sum_buy_sig_short, sum_buy_sig_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algo = stock_df_dict['TSLA'].open.pct_change()\n",
    "benchmark = stock_df_dict['NDX'].open.pct_change()\n",
    "\n",
    "'cum_returns', emp.cum_returns(algo)[-1]\n",
    "'max_drawdown', emp.max_drawdown(algo), emp.max_drawdown(benchmark)\n",
    "'annual_return', emp.annual_return(algo), emp.annual_return(benchmark)\n",
    "'annual_volatility', emp.annual_volatility(algo, period='daily')\n",
    "'calmar_ratio', emp.calmar_ratio(algo)\n",
    "'sharpe_ratio', emp.sharpe_ratio(returns=algo)\n",
    "'alpha', emp.alpha(returns=algo, factor_returns=benchmark, risk_free=0.00)\n",
    "'beta', emp.beta(returns=algo, factor_returns=benchmark, risk_free=0.00)\n",
    "\n",
    "emp_df = None\n",
    "emp_df = pd.DataFrame(columns=[\n",
    "    'symbol', 'cum_returns', 'annual_return', 'annual_volatility', 'max_drawdown', 'alpha', 'beta', 'sharpe_ratio', 'calmar_ratio'\n",
    "])\n",
    "\n",
    "for symbol in NASDAQ100:\n",
    "    algo = stock_df_dict[symbol].open.pct_change()\n",
    "    emp_df = emp_df.append(\n",
    "        {\n",
    "            'symbol': symbol,\n",
    "            'cum_returns': emp.cum_returns(algo)[-1],\n",
    "            'annual_return': emp.annual_return(algo),\n",
    "            'annual_volatility': emp.annual_volatility(algo, period='daily'),\n",
    "            'max_drawdown': emp.max_drawdown(algo),\n",
    "            'alpha': round(emp.alpha(returns=algo, factor_returns=benchmark, risk_free=0.00), 2),\n",
    "            'beta': round(emp.beta(returns=algo, factor_returns=benchmark, risk_free=0.00), 2),\n",
    "            'sharpe_ratio': emp.sharpe_ratio(returns=algo),\n",
    "            'calmar_ratio': emp.calmar_ratio(algo)\n",
    "        },\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "# emp_df\n",
    "# emp_df.sort_values('cum_returns', ascending=False)\n",
    "# emp_df.sort_values('sharpe_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "show_df = None\n",
    "show_df = stock_df_dict['NDX'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# %xmode\n",
    "\n",
    "PROPERTY = START_MONEY\n",
    "CASH = START_MONEY\n",
    "\n",
    "order_df = None\n",
    "order_df = pd.DataFrame(columns=[\n",
    "    'buy_date', 'symbol', 'buy_count', 'buy_price', 'buy_reason', 'sell_date', 'sell_price', 'sell_reason', 'profit', 'cash', 'property'\n",
    "])\n",
    "count_day = 0\n",
    "yesterday = None\n",
    "miss_buy_short = 0\n",
    "miss_buy_long = 0\n",
    "\n",
    "for today in pd.period_range(start=start_date, end=end_date, freq='D'):\n",
    "    count_day += 1\n",
    "    \n",
    "    if yesterday is None:\n",
    "        yesterday = today\n",
    "        continue\n",
    "\n",
    "    if today not in stock_df_dict['NDX'].index:\n",
    "        continue\n",
    "\n",
    "    if IS_HAPPYMONEY:        \n",
    "        if PROPERTY > START_MONEY * 2:\n",
    "            HAPPY_MONEY += 50000\n",
    "            PROPERTY -= 50000\n",
    "            CASH = PROPERTY\n",
    "    \n",
    "    # 买卖过程\n",
    "    for symbol in NASDAQ100[:]:\n",
    "#     for symbol in ['TSLA']:\n",
    "        if symbol in ['ALGN', 'ROST', 'ORLY', 'ESRX', 'ULTA', 'REGN', 'MNST']:\n",
    "#             continue\n",
    "            pass\n",
    "\n",
    "        if symbol == 'NDX':\n",
    "            continue\n",
    "        \n",
    "        if today not in stock_df_dict[symbol].index or yesterday not in stock_df_dict[symbol].index:\n",
    "            continue\n",
    "            \n",
    "        # TIME TEST\n",
    "#         print(order_df)\n",
    "#         print(order_df.columns)\n",
    "        \n",
    "#         %timeit (len(order_df[order_df['symbol'] == symbol]) != 0)\n",
    "#         %timeit order_df[order_df['symbol'] == symbol].shape[0] != 0\n",
    "#         %timeit n_order_df = order_df.values\n",
    "#         %timeit len(n_order_df[n_order_df[:, 1] == symbol]) != 0\n",
    "#         %timeit (len(order_df[(order_df['symbol'] == symbol) & (order_df['sell_price'] == 0)]) == 0)\n",
    "\n",
    "\n",
    "#         iiidx = stock_df_dict[symbol].index.get_loc(today)\n",
    "#         print(iiidx, type(iiidx))\n",
    "#         %timeit stock_df_dict[symbol].loc[today]\n",
    "#         %timeit n_stock_df = stock_df_dict[symbol].values\n",
    "#         %timeit n_stock_df[iiidx]\n",
    "        \n",
    "#         %timeit (stock_df_dict[symbol].loc[today, 'open'] >= stock_df_dict[symbol].loc[today, 'rolling_max'])\n",
    "#         %timeit (stock_df_dict[symbol].loc[today, 'open'] >= stock_df_dict[symbol].loc[today, 'rolling_max'])\n",
    "\n",
    "#         %timeit int(stock_df_dict[symbol].shift(1).loc[today, 'Unit'])\n",
    "#         %timeit int(CASH / stock_df_dict[symbol].loc[today, 'open'])\n",
    "#         %timeit buy_count * stock_df_dict[symbol].loc[today, 'open']\n",
    "#         %timeit stock_df_dict[symbol]\n",
    "#         %timeit stock_df_dict[symbol].loc[today, 'open']\n",
    "#         %timeit (stock_df_dict[symbol].loc[today, 'open'] > order_df[(order_df['symbol'] == symbol) & (order_df['sell_price'] == 0)].buy_price.iloc[-1] + 0.5 * stock_df_dict[symbol].shift(1).loc[today, 'N'])\n",
    "        \n",
    "#         n_order_df = order_df.values\n",
    "#         n_stock_df = stock_df_dict[symbol].values\n",
    "#         today_idx = stock_df_dict[symbol].index.get_loc(today)\n",
    "#         is_has_order = (len(n_order_df[n_order_df[:, 1] == symbol]) != 0)\n",
    "#         is_order_soldout = not is_has_order and (len(n_order_df[n_order_df[:, 6] == symbol]) == 0)\n",
    "        \n",
    "#         is_has_order = (len(order_df[order_df['symbol'] == symbol]) != 0)\n",
    "#         is_order_soldout = (len(order_df[(order_df['symbol'] == symbol) & (order_df['sell_price'] == 0)]) == 0)\n",
    "        \n",
    "    \n",
    "#         '''\n",
    "#         'buy_date', 'symbol', 'buy_count', 'buy_price', 'buy_reason', 'sell_date', 'sell_price', 'sell_reason', 'profit', 'cash', 'property'\n",
    "#         stock_df['ROLLING_%d_MAX' % TURTLE_SHORT_BUY_N] = stock_df['open'].rolling(TURTLE_SHORT_BUY_N).max()\n",
    "#         stock_df['ROLLING_%d_MIN' % TURTLE_SHORT_SELL_N] = stock_df['open'].rolling(TURTLE_SHORT_SELL_N).min()\n",
    "#         stock_df['ROLLING_%d_MAX' % TURTLE_LONG_BUY_N] = stock_df['open'].rolling(TURTLE_LONG_BUY_N).max()\n",
    "#         stock_df['ROLLING_%d_MIN' % TURTLE_LONG_SELL_N] = stock_df['open'].rolling(TURTLE_LONG_SELL_N).min()\n",
    "#         '''\n",
    "\n",
    "        today_market = stock_df_dict[symbol].loc[today]\n",
    "        \n",
    "        # 突破下行趋势，清仓退出\n",
    "        order_arr = order_df.to_records(index=False)\n",
    "        if len(order_arr[(order_arr.symbol == symbol) & (order_arr.sell_price == 0)] ) != 0:\n",
    "            is_sell = False\n",
    "            for idx in order_df[(order_df['symbol'] == symbol) & (order_df['sell_price'] == 0)].index:\n",
    "                cur_order = order_df.loc[idx]\n",
    "                if cur_order.buy_reason == 'SHORT':\n",
    "                    is_sell = (today_market.open <= today_market['ROLLING_%d_MIN' % TURTLE_SHORT_SELL_N])\n",
    "                if cur_order.buy_reason == 'LONG':\n",
    "                    is_sell = (today_market.open <= today_market['ROLLING_%d_MIN' % TURTLE_LONG_SELL_N])\n",
    "                if is_sell:\n",
    "                    CASH += cur_order.buy_count * today_market.open\n",
    "                    order_df.loc[idx, 'sell_date'] = today\n",
    "                    order_df.loc[idx, 'sell_price'] = today_market.open\n",
    "                    order_df.loc[idx, 'sell_reason'] = 'EXIT'\n",
    "                    order_df.loc[idx, 'profit'] = \\\n",
    "                        (today_market.open - cur_order.buy_price) * cur_order.buy_count\n",
    "#                 print(today, '退出', stock_df_dict[symbol].loc[today, 'open'], CASH)\n",
    "\n",
    "\n",
    "        # 突破上行趋势，就买一份\n",
    "        order_arr = order_df.to_records(index=False)\n",
    "        if today_market.MA60 >= today_market.MA180:\n",
    "#         if today_market.MA30 >= today_market.MA180:\n",
    "            is_buy = False\n",
    "            if today_market.open >= today_market['ROLLING_%d_MAX' % TURTLE_LONG_BUY_N]:\n",
    "                is_buy = True\n",
    "                buy_reason = 'LONG'\n",
    "            elif False and today_market.open >= today_market['ROLLING_%d_MAX' % TURTLE_SHORT_BUY_N]:\n",
    "                is_buy = True\n",
    "                buy_reason = 'SHORT'\n",
    "            if is_buy:\n",
    "                buy_count = 0\n",
    "                \n",
    "                if IS_SLIPPAGE:\n",
    "                    buy_price = today_market.open * (1 + random.randint(0, 20) / 1000)\n",
    "                else:\n",
    "                    buy_price = today_market.open\n",
    "\n",
    "                if CASH >= START_MONEY / TURTLE_POS:\n",
    "                    buy_count = int((START_MONEY / TURTLE_POS) / buy_price)\n",
    "                \n",
    "                if IS_RANDOM_BUY:\n",
    "                    if random.randint(0, 100) > 50:\n",
    "                        buy_count = 0\n",
    "\n",
    "                if buy_count > 0:\n",
    "                    CASH -= buy_count * buy_price\n",
    "#                     print(today, '建仓', buy_count, stock_df_dict[symbol].loc[today, 'open'], CASH)\n",
    "                    order_df = order_df.append(\n",
    "                        {\n",
    "                            'buy_date': today,\n",
    "                            'symbol': symbol,\n",
    "                            'buy_count': buy_count,\n",
    "                            'buy_price': today_market.open,\n",
    "                            'buy_reason': buy_reason,\n",
    "                            'sell_date': pd.np.nan,\n",
    "                            'sell_price': 0,\n",
    "                            'profit': 0,\n",
    "                            'cash': CASH,\n",
    "                            'property': PROPERTY,\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                    )\n",
    "                else:\n",
    "                    if buy_reason == 'LONG':\n",
    "                        miss_buy_long += 1\n",
    "                    elif buy_reason == 'SHORT':\n",
    "                        miss_buy_short += 1\n",
    "            \n",
    "    # 每天盘点财产\n",
    "    show_df.loc[today, 'CASH_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)] = CASH\n",
    "    PROPERTY = CASH + \\\n",
    "        sum(\n",
    "            [\n",
    "                stock_df_dict[order_df.loc[idx, 'symbol']][:today].iloc[-1].open * order_df.loc[idx, 'buy_count'] \\\n",
    "                for idx in order_df.loc[order_df['sell_price']==0].index\n",
    "            ]\n",
    "        )\n",
    "    show_df.loc[today, 'PROPERTY_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)] = PROPERTY\n",
    "\n",
    "    yesterday = today\n",
    "            \n",
    "\n",
    "print(CASH)\n",
    "print(HAPPY_MONEY)\n",
    "print(PROPERTY)\n",
    "\n",
    "s_p = stock_df_dict['NDX'][start_date:].iloc[0].open\n",
    "e_p = stock_df_dict['NDX'].iloc[-1].open\n",
    "print('NDX', s_p, e_p, e_p / s_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'ALL'\n",
    "'start_date', start_date\n",
    "'end_date', end_date\n",
    "'TURTLE_POS', TURTLE_POS\n",
    "'TURTLE_SHORT_BUY_N', TURTLE_SHORT_BUY_N\n",
    "'TURTLE_SHORT_SELL_N', TURTLE_SHORT_SELL_N\n",
    "'TURTLE_LONG_BUY_N', TURTLE_LONG_BUY_N\n",
    "'TURTLE_LONG_SELL_N', TURTLE_LONG_SELL_N\n",
    "'IS_HAPPYMONEY', IS_HAPPYMONEY\n",
    "'IS_TAX', IS_TAX\n",
    "'IS_SLIPPAGE', IS_SLIPPAGE\n",
    "'IS_RANDOM_BUY', IS_RANDOM_BUY\n",
    "'START_MONEY', START_MONEY\n",
    "\n",
    "'len(order_df)', len(order_df)\n",
    "sum_profit = sum(list(order_df['profit']))\n",
    "'sum_profit', sum_profit\n",
    "# sum_tax = sum(list(order_df_TB['tax']))\n",
    "sum_tax = 0\n",
    "'sum_tax', sum_tax\n",
    "'win rate', len(order_df[order_df.profit > 0]) / len(order_df[order_df.profit != 0])\n",
    "# 'REWARD', ((sum_profit - sum_tax) / START_MONEY + 1) ** (365 / count_day)\n",
    "'len(order_df[order_df.profit != 0])', len(order_df[order_df.profit != 0])\n",
    "'len(order_df[order_df.profit > 0])', len(order_df[order_df.profit > 0])\n",
    "'order LONG', len(order_df[order_df.buy_reason == 'LONG'])\n",
    "len(order_df[(order_df.buy_reason == 'LONG') & (order_df.profit > 0)])\n",
    "sum(list(order_df[order_df.buy_reason == 'LONG']['profit']))\n",
    "'order SHORT', len(order_df[order_df.buy_reason == 'SHORT'])\n",
    "len(order_df[(order_df.buy_reason == 'SHORT') & (order_df.profit > 0)])\n",
    "sum(list(order_df[order_df.buy_reason == 'SHORT']['profit']))\n",
    "\n",
    "# order_df\n",
    "# order_df.loc[order_df['sell_price']==0]\n",
    "\n",
    "calc_df = order_df.copy()\n",
    "calc_df['profit_pct'] = calc_df['profit'] / (calc_df['buy_count'] * calc_df['buy_price'])\n",
    "# calc_df[calc_df.symbol == 'BIDU']\n",
    "# calc_df[calc_df.profit > 0]\n",
    "# calc_df\n",
    "\n",
    "# order_df[order_df.profit > 0]\n",
    "\n",
    "# csv_file = 'E:/Dev/result/T_TURTLE_POS%d_TURTLE_BUY_N%d_TURTLE_SELL_N%d_START_MONEY%d_%s_%s.csv' % \\\n",
    "#     (TURTLE_POS, TURTLE_BUY_N, TURTLE_SELL_N, START_MONEY, start_date, end_date)\n",
    "# calc_df.to_csv(csv_file)\n",
    "\n",
    "# list(show_df.dropna(how='any', inplace=False).PROPERTY_TURTLE_20_60_60.apply(int).tail(50))\n",
    "# list(show_df.open.apply(int).tail(50))\n",
    "\n",
    "df = show_df.dropna(how='any', inplace=False).copy()\n",
    "algo = df['PROPERTY_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)].pct_change()\n",
    "benchmark = df.open.pct_change()\n",
    "\n",
    "'cum_returns', emp.cum_returns(algo)[-1], emp.cum_returns(benchmark)[-1]\n",
    "'max_drawdown', emp.max_drawdown(algo), emp.max_drawdown(benchmark)\n",
    "'annual_return', emp.annual_return(algo), emp.annual_return(benchmark)\n",
    "'annual_volatility', emp.annual_volatility(algo, period='daily')\n",
    "'calmar_ratio', emp.calmar_ratio(algo)\n",
    "'sharpe_ratio', emp.sharpe_ratio(returns=algo)\n",
    "'alpha', emp.alpha(returns=algo, factor_returns=benchmark, risk_free=0.00)\n",
    "'beta', emp.beta(returns=algo, factor_returns=benchmark, risk_free=0.00)\n",
    "\n",
    "'ALL DAY', len(df)\n",
    "'CASH_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)\n",
    "'PROPERTY_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)\n",
    "'CASH NOT USED DAY', \\\n",
    "    len(df[df['CASH_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)] > \\\n",
    "           df['PROPERTY_TURTLE_%d_%d_%d' % (TURTLE_POS, TURTLE_LONG_BUY_N, TURTLE_LONG_SELL_N)] / TURTLE_POS])\n",
    "'MISS_BUY_SIGNAL_LONG', miss_buy_long\n",
    "'MISS_BUY_SIGNAL_SHORT', miss_buy_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bad_stock_cnt = 0\n",
    "s_p = stock_df_dict['NDX'][start_date:].iloc[0].open\n",
    "e_p = stock_df_dict['NDX'].iloc[-1].open\n",
    "benchmark_return = e_p / s_p\n",
    "for symbol, stock_df in stock_df_dict.items():\n",
    "    df = stock_df.loc[start_date:end_date, 'close']\n",
    "#     print(df)\n",
    "    s_p = df.head(1).values\n",
    "    e_p = df.tail(1).values\n",
    "#     print(symbol, s_p, e_p, e_p / s_p)\n",
    "    if e_p / s_p < benchmark_return:\n",
    "        bad_stock_cnt += 1\n",
    "bad_stock_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "# order_df_TB\n",
    "bar_df = order_df.copy()\n",
    "df = bar_df.sort_values(by=['profit'])\n",
    "# df\n",
    "\n",
    "bins = [100 * x for x in range(-200, 500)]\n",
    "# bins\n",
    "\n",
    "cats = pd.cut(df['profit'], bins)\n",
    "# cats\n",
    "\n",
    "def get_stats(group):\n",
    "    return {'count': group.count()}\n",
    "\n",
    "grouped = df['profit'].groupby(cats)\n",
    "bin_counts = grouped.apply(get_stats).unstack()\n",
    "bin_counts.reset_index(inplace=True, drop=False)\n",
    "bin_counts['profit'] = bin_counts['profit'].apply(str)\n",
    "# bin_counts\n",
    "\n",
    "# df['profit'].hist(bins=10)\n",
    "\n",
    "# bin_counts.plot(kind='barh', alpha=0.5, rot=0)\n",
    "\n",
    "# display_charts(bin_counts, kind='bar', x='profit', figsize=(900, 600), logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "df = show_df.dropna(how='any', inplace=False).copy()\n",
    "# df.drop(columns=['open', 'high', 'low', 'o_pct_chg', 'TR', 'N'], inplace=True)\n",
    "df.columns\n",
    "\n",
    "df['close'] = (df['close'] - df.iloc[0]['close']) / df.iloc[0]['close']\n",
    "ax = df.plot(kind='line', y='close', label='NDX_%.2f' % df.iloc[-1]['close'], linewidth=1, grid=True)\n",
    "for col in sorted(df.columns):\n",
    "    if 'PROPERTY' in col:\n",
    "        df[col] = (df[col] - df.iloc[1][col]) / df.iloc[0][col]\n",
    "        ax = df.plot(kind='line', y=col, secondary_y=False, label='%s_%.2f' % (col, df.iloc[-1][col]), linewidth=1, grid=True, ax=ax)\n",
    "\n",
    "# display_charts(df, kind='line', figsize=(900, 600), logy=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
